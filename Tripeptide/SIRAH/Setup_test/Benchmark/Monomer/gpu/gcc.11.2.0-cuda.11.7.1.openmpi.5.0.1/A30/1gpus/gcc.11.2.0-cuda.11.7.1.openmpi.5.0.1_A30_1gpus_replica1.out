                      :-) GROMACS - gmx mdrun, 2024.2 (-:

Executable:   /opt/apps/gromacs/2024.2/gcc/11.2.0/cuda/11.7.1/openmpi/5.0.1/bin/gmx_mpi
Data prefix:  /opt/apps/gromacs/2024.2/gcc/11.2.0/cuda/11.7.1/openmpi/5.0.1
Working dir:  /dfs9/tw/yuanmis1/mrsec/ML-MD-Peptide/SIRAH/Setup_test/Benchmark/gpu/gcc.11.2.0-cuda.11.7.1.openmpi.5.0.1/A30/1gpus
Command line:
  gmx_mpi mdrun -s /dfs9/tw/yuanmis1/mrsec/ML-MD-Peptide/SIRAH/Setup_test/Benchmark/C_A_A_SIRAH_md.tpr -deffnm C_A_A_SIRAH_md_A30_1gpus_replica1 -nb gpu -pme gpu -bonded gpu -update gpu

Compiled SIMD is AVX2_128, but AVX_512 might be faster (see log).
Reading file /dfs9/tw/yuanmis1/mrsec/ML-MD-Peptide/SIRAH/Setup_test/Benchmark/C_A_A_SIRAH_md.tpr, VERSION 2024.2 (single precision)
Changing nstlist from 10 to 25, rlist from 1.224 to 1.396

1 GPU selected for this run.
Mapping of GPU IDs to the 2 GPU tasks in the 1 rank on this node:
  PP:0,PME:0
PP tasks will do (non-perturbed) short-ranged and most bonded interactions on the GPU
PP task will update and constrain coordinates on the GPU
PME tasks will do all aspects on the GPU
Using 1 MPI process

Non-default thread affinity set, disabling internal thread affinity

Using 40 OpenMP threads 

starting mdrun 'Protein in water'
10000 steps,    200.0 ps.

Writing final coordinates.

NOTE: 11 % of the run time was spent in pair search,
      you might want to increase nstlist (this has no effect on accuracy)

               Core t (s)   Wall t (s)        (%)
       Time:       91.970        2.300     3998.9
                 (ns/day)    (hour/ns)
Performance:     7514.070        0.003

GROMACS reminds you: "It's So Fast It's Slow" (F. Black)

