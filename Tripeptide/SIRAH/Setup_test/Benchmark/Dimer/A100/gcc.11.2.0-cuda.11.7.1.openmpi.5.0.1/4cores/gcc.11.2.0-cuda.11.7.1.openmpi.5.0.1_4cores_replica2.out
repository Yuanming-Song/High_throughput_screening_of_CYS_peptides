                      :-) GROMACS - gmx mdrun, 2024.2 (-:

Executable:   /opt/apps/gromacs/2024.2/gcc/11.2.0/cuda/11.7.1/openmpi/5.0.1/bin/gmx_mpi
Data prefix:  /opt/apps/gromacs/2024.2/gcc/11.2.0/cuda/11.7.1/openmpi/5.0.1
Working dir:  /dfs9/tw/yuanmis1/mrsec/ML-MD-Peptide/SIRAH/Setup_test/Benchmark/Dimer/A100/gcc.11.2.0-cuda.11.7.1.openmpi.5.0.1/4cores
Command line:
  gmx_mpi mdrun -s /dfs9/tw/yuanmis1/mrsec/ML-MD-Peptide/SIRAH/Setup_test/Benchmark/Dimer/C_A_A_SIRAH_md.tpr -deffnm C_A_A_SIRAH_md_replica2 -nb gpu -pme gpu -bonded gpu -update gpu

Compiled SIMD is AVX2_128, but AVX_512 might be faster (see log).
Reading file /dfs9/tw/yuanmis1/mrsec/ML-MD-Peptide/SIRAH/Setup_test/Benchmark/Dimer/C_A_A_SIRAH_md.tpr, VERSION 2024.2 (single precision)
Changing nstlist from 10 to 25, rlist from 1.225 to 1.398

1 GPU selected for this run.
Mapping of GPU IDs to the 2 GPU tasks in the 1 rank on this node:
  PP:0,PME:0
PP tasks will do (non-perturbed) short-ranged and most bonded interactions on the GPU
PP task will update and constrain coordinates on the GPU
PME tasks will do all aspects on the GPU
Using 1 MPI process
Using 4 OpenMP threads 

starting mdrun 'Protein in water'
10000 steps,    200.0 ps.

Writing final coordinates.

NOTE: 35 % of the run time was spent in pair search,
      you might want to increase nstlist (this has no effect on accuracy)

               Core t (s)   Wall t (s)        (%)
       Time:        9.090        2.274      399.8
                 (ns/day)    (hour/ns)
Performance:     7600.355        0.003

GROMACS reminds you: "Get Down In 3D" (George Clinton)

